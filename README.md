# Khipu 2025 Practicals (Coming soon!)

## Day 1 

| Topic ðŸ’¥ | Description ðŸ“˜ |
|:--- |----------------------------------------------------------|
[Introduction to ML Using JAX](https://github.com/khipu-ai/practicals-2025/blob/main/notebooks/Intro_to_ML.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khipu-ai/practicals-2025/blob/main/notebooks/Intro_to_ML.ipynb) | This tutorial introduces basic concepts in Machine Learning and their implementation using JAX. JAX is a high performance Python library for computation, optimization and model learning.  | 
[**Let's map Chile!** Intro to Geospatial Machine Learning](https://github.com/khipu-ai/practicals-2025/blob/main/notebooks/Geospatial_Machine_Learning.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khipu-ai/practicals-2025/blob/main/notebooks/Geospatial_Machine_Learning.ipynb) | Satellite imagery and machine learning (ML) can help address many problems addressing the global south such as climate related challenges in food and water security, biodiversity, energy, and public health. To this end, this practical is designed to provide an introductory tutorial on geospatial machine learning for agriculture, particularly to classify farm-level crop types in Chile using Sentinel-2 satellite imagery. Starting with an introductory session on key concepts of geospatial ML, the tutorial delves into ML development, validation, and performance evaluation techniques. | 
[Foundations of LLMs](https://github.com/khipu-ai/practicals-2025/blob/main/notebooks/Foundations_of_LLMs.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khipu-ai/practicals-2025/blob/main/notebooks/Foundations_of_LLMs.ipynb) | Foundations of LLMs is your gateway to the fascinating world of Large Language Models (LLMs)! In this practical, we shall dive into the core principles of transformers, the cutting-edge technology behind models like GPT, Llama and Gemini, and explore how these impressive AI systems create such realistic and engaging text. You'll also get hands-on experience training your very own Language Model!. | 

## Day 2

| Topic ðŸ’¥ | Description ðŸ“˜ |
|:--- |----------------------------------------------------------|
| [Graph Neural Networks](https://github.com/khipu-ai/practicals-2025/blob/main/notebooks/Graph_Neural_Networks.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khipu-ai/practicals-2025/blob/main/notebooks/Graph_Neural_Networks.ipynb) | In this tutorial, we will be learning about Graph Neural Networks (GNNs), a topic which has exploded in popularity in both research and industry. We will start with a refresher on graph theory, then dive into how GNNs work from a high level. Next we will cover some popular GNN implementations and see how they work in practice. |
| [Vision-Language Models](https://github.com/khipu-ai/practicals-2025/blob/main/notebooks/Vision_Language_Models.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khipu-ai/practicals-2025/blob/main/notebooks/Vision_Language_Models.ipynb) | In this tutorial we'll explore how we can use image-text data to build Vision Language Models ðŸš€. We'll start with an introduction to multimodal understanding that describes the main components of a Vision Lanugage Model and provides a brief history of how these have evolved in recent years. Then, we'll dive deep into Contrastive Language-Image Pre-training (CLIP), a model for learning general representation from image-text pairs that can be used for a wide range of downstream tasks. We'll then explore how CLIP can be used for semantic image search followed by a showcase of its failure cases. Finally, we'll finetune together PaliGemma, a powerful 3B vision language model. |
| [Socio-Cultural Evaluation of AI](https://github.com/khipu-ai/practicals-2025/blob/main/notebooks/Socio-Cultural%20Evaluation%20of%20AI.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1kSAzvnXkvI4uHOiI2S9MVDsSB5Pl6yaq?usp=sharing) | In this tutorial, you will examine how AI systems reflect and reinforce socio-cultural biases. Through hands-on activities and group discussions, you will analyze biases in large language models, assess culturally situated benchmarks like SeeGULL and HESEIA from different perspectives, and experiment with bias detection tools. You will also step into the role of a crowdworker to understand how annotation decisions shape AI outcomes. No prior NLP knowledge is required. This session encourages critical reflection on bias from your own cultural and personal perspective while connecting with a diverse network of colleagues across Latin America. |

## Day 3

| Topic ðŸ’¥ | Description ðŸ“˜ |
|:--- |----------------------------------------------------------|
|[Diffusion Models](https://github.com/khipu-ai/practicals-2025/blob/main/notebooks/Diffusion_Models.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khipu-ai/practicals-2025/blob/main/notebooks/Diffusion_Models.ipynb) | This practical will walk you through the challenges involved in developing an effective generative model for the particular case of Denoise Diffusion Models (a.k.a. a Score-Based Generative Model), the backbone of the popular text-to-image and text-to-video models seen online.|
[Reinforcement Learning](https://github.com/khipu-ai/practicals-2025/blob/main/notebooks/Reinforcement_Learning.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khipu-ai/practicals-2025/blob/main/notebooks/Reinforcement_Learning.ipynb) <br /> <br />[Model Predictive Control](https://github.com/khipu-ai/practicals-2025/blob/main/notebooks/Model_Predictive_Contol.ipynb)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khipu-ai/practicals-2025/blob/main/notebooks/Model_Predictive_Contol.ipynb) | In Reinforcement Learning (RL),  an _agent_ is trained to take the best actions in an environment so as to maximize a given reward in the long run. RL has seen tremendous success on a wide range of challenging problems such as learning to play complex video games like [Atari](https://www.deepmind.com/blog/agent57-outperforming-the-human-atari-benchmark) and [StarCraft II](https://www.deepmind.com/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii). In this introductory tutorial we will explore various RL and Model Predictive Control (MPC) approaches for solving the classic [CartPole](https://www.gymlibrary.ml/environments/classic_control/cart_pole/), an inverted pendulum system, where an agent must learn to balance a vertical pole by displacing the cart.| 
|[Resource-efficient NLP](https://github.com/khipu-ai/practicals-2025/blob/main/notebooks/Low_Resource_LLM_ES.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khipu-ai/practicals-2025/blob/main/notebooks/Low_Resource_LLM_ES.ipynb) | Low-resource NLP (Natural Language Processing) refers to the study and development of NLP models and systems for languages, tasks, or domains that have limited data and resources available. These can include languages with fewer digital text corpora, limited computational tools, or less-developed linguistic research. In this practical, we will explore data scarcity and compute resource limitations in low-resource NLP, and introduce some ways to address these challenges with parameter-efficient finetuning of LLMs. |


## Extra

| Topic ðŸ’¥ | Description ðŸ“˜ |
|:--- |----------------------------------------------------------|
[Basics of JAX](https://github.com/khipu-ai/practicals-2025/blob/main/notebooks/Jax_Basics.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khipu-ai/practicals-2025/blob/main/notebooks/Jax_Basics.ipynb) | This standalone notebook covers the fundamentals of JAX, a Python library for accelerator-oriented array computation and program transformation, designed for high-performance numerical computing and large-scale machine learning. This notebook is recommended if you are new to JAX and want to warm up before attending the practicals. | 

## Attribution

Some of the above practicals (including intro to LLMs, parameter efficient ML, geospatial ML, diffusion, RL) are derived from the  [practicals developed for Indaba 2024](https://github.com/deep-learning-indaba/indaba-pracs-2024) with kind permission from the authors. See each notebook for specific attribution information.
